logging:
  level: INFO

training:
  epochs: 1
  batch_size: 8
  gradient_accumulation: 1
  mixed_precision: bf16
  grad_clip_norm: 1.0
  log_interval: 5
  max_steps: 200
  output_dir: artifacts

optimizer:
  lr: 0.0003
  weight_decay: 0.01
  betas: [0.9, 0.98]

scheduler:
  warmup_steps: 100
  total_steps: 2000

dataset:
  num_samples: 10000
  sequence_length: 64
  dense_dim: 128
  sparse_features: 32
  vocab_size: 60000
  num_dense_features: 16
  seed: 42

model:
  vocab_size: 60000
  embedding_dim: 192
  num_dense_features: 16
  dense_dim: 128
  model_dim: 768
  num_heads: 12
  num_layers: 8
  dropout: 0.1
  mlp_hidden_dim: 2048

fsdp:
  sharding_strategy: full_shard
  backward_prefetch: BACKWARD_PRE
  use_orig_params: true
  limit_all_gathers: true
  forward_prefetch: true
  sync_module_states: true
  param_init_device: cpu

compile:
  enabled: false
  backend: inductor
  mode: max-autotune
  fullgraph: false
  dynamic: false
  options: {}

distributed:
  mode: fsdp
  enable_overlap: true
  overlap_reduce_scatter: true
  overlap_clone_for_reduce_scatter: true

dataloader:
  num_workers: 4
  pin_memory: true

profiling:
  enabled: false
  wait: 1
  warmup: 1
  active: 2
  repeat: 1
  record_shapes: true
  profile_memory: true
  with_stack: false
  with_flops: false
  tensorboard: true
  chrome_trace: false
  trace_filename: trace.json
